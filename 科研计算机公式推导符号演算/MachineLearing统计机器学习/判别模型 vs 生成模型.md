# 生成模型






[\[白话解析\] 深入浅出最大熵模型](https://www.cnblogs.com/rossiXYZ/p/12244760.html)

###  判别模型 vs 生成模型

分类问题，就是给定一个数据 x，要判断它对应的标签 y。分类模型有判别模型和生成模型两种。

####  生成模型 (**Generative**)

生成模型之所以叫生成模型，是因为，它背后的思想是 x是特征，y是标签，什么样的标签就会**生成**什么样的特征。好比说，标签是大象，那么可能的特征就有大耳朵，长鼻子等等。模型表示了**给定输入X产生输出Y的生成关系**。

生成模型就是要学习观测数据 x 和隐藏类别 y 的**联合概率分布P(x,y)**，然后根据贝叶斯公式来求得条件概率P(y|x)，预测条件概率最大的y。也就是说，**在训练阶段是只对P(X,Y)建模**，需要确定这个联合概率分布的所有的信息参数。具体流程是：

-   先从训练样本数据中，将所有的数据的分布情况摸透，然后最终确定一个分布，来作为所有的输入数据的分布，并且他是一个联合分布 P(X,Y) (注意 X 包含所有的特征 Xi, Y 包含所有的label Yi, 要对每个label Yi 都需要建模)。
-   然后来了新的样本数据再对新的样本计算P(Y|X) ，导出Y , 最终选择最优概率的label为结果，所以没有什么判别边界。

再过一遍生成式模型的工作流程。


学习阶段，建模：

$P(X,Y)=P(X|Y)P(Y)P(X,Y)=P(X|Y)P(Y)$

然后 根据新的X，导出 Y：

$P(Y|X)=P(X,Y)P(X)P(Y|X)=P(X,Y)P(X)$

**生成式模型的优点**在于，所包含的信息非常齐全，我称之为“上帝信息”，所以不仅可以用来输入label，还可以干其他的事情。生成式模型关注结果是如何产生的。但是生成式模型需要非常充足的数据量以保证采样到了数据本来的面目，所以速度相比会慢。或者说生成模型是在模拟数据真实分布。

**生成模型的例子**：HMM / 朴素贝叶斯。Naive Bayes 需要同时对输入X和输出Y进行建模，得到联合分布P(X,Y)，因此是生成模型。由于X是个比较复杂的东西，建模起来很痛苦，于是 Naive Bayes 不得不做了很强的假设，从此一辈子戴上了 “Naive” 的帽子。

####   判别模型(**Discriminative**)

**判别模型是直接对 条件概率 P(Y|X) 建模**，就是说，直接根据X特征来对Y建模训练。通俗的解释为在给定特征数值后预测结果出现的概率。

判别模型直接将数据的 Y（或者label），根据所提供的 X (features)来学习。训练过程是确定构建 P(Y|X) 模型里面 “复杂映射关系” 中的参数。

判别模型对所有的样本只构建一个模型，确认**总体判别边界**。观测到输入什么特征，就预测最可能的label，最后画出了一个明显或者比较明显的边界（具体可以通过复杂的函数映射，或者决策叠加等等mechanism做到）。

或者说，判别模型之所以是判别模型，是因为**由于去掉了独立性假设，所以不能给出联合概率分布，只能求后验概率，所以是判别模型**。

**判别模型的例子**是: 逻辑回归 / SVM / CRF。

**判别模型的优点**是：对数据量要求没生成式的严格，速度也会快，小数据量下准确率也会好些。
