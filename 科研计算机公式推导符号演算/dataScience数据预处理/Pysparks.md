# Pysparks



Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，Spark拥有Hadoop MapReduce所具有的优点；但不同MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好 适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。

Spark提供了一个更快、更通用的数据处理平台。和Hadoop相比，Spark可以让你的程序在内存中运行时速度提升100倍，或者在磁盘上运行时速度提升10倍。去年，在100 TB Daytona GraySort比赛中，Spark战胜了Hadoop，它只使用了十分之一的机器，但运行速度提升了3倍。Spark也已经成为针对 PB 级别数据排序的最快的开源引擎。

Spark支持Scala、Java、Python、R等接口，本文均使用Python环境进行学习。



https://www.jianshu.com/p/ede10338a932










