# NLTK

如何用 Python 中的 NLTK 对中文进行分析和处理？ - 路人甲的回答 - 知乎
https://www.zhihu.com/question/20922994/answer/156070002

github.com/nltk/nltk   仓库



英文文档

nltk.org



中文文档





osgeo.cn/nltk/





## 英文教程：nltk.org/book_1ed/




*The book is being updated for Python 3 and NLTK 3. Please see [http://www.nltk.org/book](http://www.nltk.org/book).*

0. [Preface](http://www.nltk.org/book_1ed/ch00.html) ([extras](http://www.nltk.org/book_1ed/ch00-extras.html))

1. [Language Processing and Python](http://www.nltk.org/book_1ed/ch01.html) ([extras](http://www.nltk.org/book_1ed/ch01-extras.html))

2. [Accessing Text Corpora and Lexical Resources](http://www.nltk.org/book_1ed/ch02.html) ([extras](http://www.nltk.org/book_1ed/ch02-extras.html))

3. [Processing Raw Text](http://www.nltk.org/book_1ed/ch03.html)

4. [Writing Structured Programs](http://www.nltk.org/book_1ed/ch04.html) ([extras](http://www.nltk.org/book_1ed/ch04-extras.html))

5. [Categorizing and Tagging Words](http://www.nltk.org/book_1ed/ch05.html)

6. [Learning to Classify Text](http://www.nltk.org/book_1ed/ch06.html) ([extras](http://www.nltk.org/book_1ed/ch06-extras.html))

7. [Extracting Information from Text](http://www.nltk.org/book_1ed/ch07.html)

8. [Analyzing Sentence Structure](http://www.nltk.org/book_1ed/ch08.html) ([extras](http://www.nltk.org/book_1ed/ch08-extras.html))

9. [Building Feature Based Grammars](http://www.nltk.org/book_1ed/ch09.html)

10. [Analyzing the Meaning of Sentences](http://www.nltk.org/book_1ed/ch10.html) ([extras](http://www.nltk.org/book_1ed/ch10-extras.html))

11. [Managing Linguistic Data](http://www.nltk.org/book_1ed/ch11.html)

12. [Afterword: Facing the Language Challenge](http://www.nltk.org/book_1ed/ch12.html)

[Bibliography](http://www.nltk.org/book_1ed/bibliography.html)  
[Term Index](http://www.nltk.org/book_1ed/term_index.html)

[Errata](https://raw.github.com/nltk/nltk_book/master/book/errata.txt) (corrected here, and in the second printing of book (January 2010))

**Translations**: [Book](http://www.oreilly.co.jp/books/9784873114705/) (jp), [Prefácio](http://www.nltk.org/book_1ed/ch00-pt.html) (pt), [Przedmowa](http://www.nltk.org/book-pl/ch00-pl.html) (pl)

**Reviews**: [LanguageLog](http://languagelog.ldc.upenn.edu/nll/?p=1554), [Amazon.com](http://www.amazon.com/product-reviews/0596516495/?showViewpoints=1), [Slashdot.org](http://slashdot.org/~beachdog/journal/233647), [Dr Dobbs](http://dobbscodetalk.com/index.php?option=com_content&task=view&id=1850)

  
*This book is made available under the terms of the [Creative Commons Attribution Noncommercial No-Derivative-Works 3.0 US License](http://creativecommons.org/licenses/by-nc-nd/3.0/us/).  
Please post any questions about the materials to the [nltk-users](http://groups.google.com/group/nltk-users) mailing list. Please report any errors on the [issue tracker](https://github.com/nltk/nltk_book/issues). Note that the "extras" sections are not part of the published book, and will continue to be expanded.*





##  [推荐两份NLP读书笔记和一份NLTK书籍代码中文注释版](https://www.52nlp.cn/%e6%8e%a8%e8%8d%90%e4%b8%a4%e4%bb%bdnlp%e8%af%bb%e4%b9%a6%e7%ac%94%e8%ae%b0%e5%92%8c%e4%b8%80%e4%bb%bdnltk%e4%b9%a6%e7%b1%8d%e4%bb%a3%e7%a0%81%e4%b8%ad%e6%96%87%e6%b3%a8%e9%87%8a%e7%89%88)



推荐一下AINLP技术交流群里 zYx.tom 同学贡献给大家的两份NLP读书笔记和一份中文注释代码，包括:

《自然语言处理综论》中文版第二版学习笔记

《计算机自然语言处理》学习笔记

《Python自然语言处理》学习代码的中文注释版本：[NLTK-Python-CN](https://github.com/zhuyuanxiang/NLTK-Python-CN)

作者博客：[https://zhuyuanxiang.github.io/](https://zhuyuanxiang.github.io/)

由作者授权，我把2份pdf文件放到github上了，感兴趣的同学可以直接在github上下载：

[https://github.com/panyang/AINLP-Resource/tree/master/zYx.Tom](https://github.com/panyang/AINLP-Resource/tree/master/zYx.Tom)

《[自然语言处理综论](https://www.52nlp.cn/%e5%a6%82%e4%bd%95%e5%ad%a6%e4%b9%a0%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e8%87%aa%e7%84%b6-%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e7%bb%bc%e8%ae%ba%e8%8b%b1%e6%96%87%e7%89%88)》是NLP领域的经典著作，第一版、第二版国内都有中文翻译版，目前英文版第三版《Speech and Language Processing (3rd ed. draft)》正在撰写中，已完结的章节草稿可以直接从[slp3](https://www.52nlp.cn/%e5%a6%82%e4%bd%95%e5%ad%a6%e4%b9%a0%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e8%87%aa%e7%84%b6-%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e7%bb%bc%e8%ae%ba%e8%8b%b1%e6%96%87%e7%89%88)官网下载：[https://web.stanford.edu/~jurafsky/slp3/](https://web.stanford.edu/~jurafsky/slp3/) ，加了很多深度学习自然语言处理的相关章节，这里引用李纪为博士《[初入NLP领域的一些小建议](https://mp.weixin.qq.com/s/qnsvDQvPZSJG6rDtbFGggA)》中的一段描述，供计划学习这本书的同学参考：

> 了解NLP的最基本知识：Jurafsky和Martin的Speech and Language Processing是领域内的经典教材，里面包含了NLP的基础知识、语言学扫盲知识、基本任务以及解决思路。阅读此书会接触到很多NLP的最基本任务和知识，比如tagging, 各种parsing，coreference, semantic role labeling等等等等。这对于全局地了解NLP领域有着极其重要的意义。书里面的知识并不需要烂熟于心，但是刷上一两遍，起码对于NLP任务有基本认识，下次遇到了知道去哪里找还是非常有意义的。

《计算机自然语言处理》是哈工大王晓龙、关毅两位老师的中文NLP著作，我在刚入门NLP的时候读过，但是已经很久了，这本书在我早期的博文里记述过：[《几本自然语言处理入门书》](https://www.52nlp.cn/natural-language-processing-primer-books)，唯一的印象就是第一次了解到本科母校HIT在中文NLP领域是非常厉害的。这本书貌似已经无法在电商网站买到，感兴趣的同学可以看看zYx.Tom同学的学习笔记。

[NLTK](https://www.52nlp.cn/tag/nltk)是经典的Python NLP工具包，配套的书籍《[Natural Language Processing with Python](https://www.nltk.org/book/)》目前也有了中文翻译版本，感兴趣的同学可以参考zYx.Tom同学的这份《Python自然语言处理》学习代码的中文注释版本：[NLTK-Python-CN](https://github.com/zhuyuanxiang/NLTK-Python-CN)。

最后，欢迎大家关注[AINLP公众号](https://www.52nlp.cn/%E6%AC%A2%E8%BF%8E%E5%85%B3%E6%B3%A8ainlp-%E4%B8%80%E4%B8%AA%E6%9C%89%E8%B6%A3%E6%9C%89ai%E7%9A%84nlp%E5%85%AC%E4%BC%97%E5%8F%B7)，加入[AINLP技术交流群](https://www.52nlp.cn/%e4%ba%a4%e6%b5%81%e7%be%a4)，一起维护一个NLP技术交流环境。





## python的nltk中文使用和学习资料汇总帮你入门提高


blog.csdn.net/huyoo/article/details/12188573





nltk是一个python工具包, 用来处理和自然语言处理相关的东西. 包括分词(tokenize), 词性标注(POS), 文本分类, 等等现成的工具.

1. nltk的安装
资料1.1: 黄聪：Python+NLTK自然语言处理学习（一）：环境搭建  http://www.cnblogs.com/huangcong/archive/2011/08/29/2157437.html   这个图文并茂, 步骤清晰, 值得一看. 我想我没必要再重新写一遍了, 因为我当时也是按照他这样做的.



资料1.2: 把python自然语言处理的nltk_data打包到360云盘，然后共享给朋友们 http://www.cnblogs.com/ToDoToTry/archive/2013/01/18/2865941.html 这个是作者将接近300M的nltk_data上传到百度云了, 我觉得, 可以试试下载, 毕竟使用资料1中nltk自带的download()方法, 从官方网站下载所有的数据包需要很长时间.

补充: 有人说, 这个下载的链接已经失效了, 我把我用的nltk2.0的data目录里的zip文件打包传到百度云盘了, 290多M, 上传我费了好多时间, 你们可以去下载: http://pan.baidu.com/s/1hq7UUFU

资料1.3: Ubuntu上安装NLTK出现的问题与解决方法 http://www.cnblogs.com/mengshu-lbq/archive/2012/09/19/2694135.html 需要的看看吧

资料1.4: 安装nltk遇到的小问题 http://blog.upupbug.com/?p=106 

资料1.5  安装nltk后导入语料的时候出错, 一般是一些依赖包没安装 http://blog.tianya.cn/blogger/post_show.asp?BlogID=762305&PostID=8954744

资料1.6 NLTK中文化處理及文字筆畫音調剖析工具整合套件 http://tm.itc.ntnu.edu.tw/CNLP/?q=node/5 台湾一个大学对nltk的介绍

资料1.7 windows下如何安装NLTK，并使用模块nltk？http://zhidao.baidu.com/question/567881533.html



2. nltk初步使用入门
资料2.1  PYTHON自然语言处理中文翻译 NLTK 中文版.pdf http://ishare.iask.sina.com.cn/f/23996193.html 中文版的《PYTHON自然语言处理》 这是一个好书，强烈推荐。这本书虽然早就有人翻译成中文了，但是还有些精力旺盛的博主还在翻译，比如这位 http://www.cnblogs.com/yuxc/archive/2011/08/29/2157415.html 《Python自然语言处理》学习笔记索引。 他翻译了很多， 中英文夹杂的，精神可嘉，做法不可取。不知道别人早就翻译完了这本书吗？

资料2.2: 黄聪：Python+NLTK自然语言处理学习（二）：常用方法（similar、common_contexts、generate） http://www.cnblogs.com/huangcong/archive/2011/08/29/2158054.html  

这篇, 初步介绍了如何开始使用nltk的语料和他的一些常用方法. 有点python基础的可以直接看了.之所以放在这里, 还是因为, 只有安装好了才可以进行到这一步.



资料2.3 黄聪：Python+NLTK自然语言处理学习（三）：计算机自动学习机制 http://www.cnblogs.com/huangcong/archive/2011/08/29/2158447.html  

这一篇也挺浅显易懂的.

资料2.4 python中nltk.parse_cfg是干什么用的 求例子 http://zhidao.baidu.com/question/552627368.html 



3.nltk初中级应用
资料3.1: 可爱的 Python: 自然语言工具包入门 http://www.ibm.com/developerworks/cn/linux/l-cpnltk/

这个是ibm的砖家写的资料, 但是这个不能作为入门资料, 可以归结到初级应用资料. 对于那些动手能力弱的人, 这个文章真的不是那么好懂的, 所以不适合入门看, 而适合那些喜欢写代码, 喜欢鼓捣折腾的人看.



资料3.2 词性标注 http://blog.csdn.net/fxjtoday/article/details/5841453 这篇文章介绍了默认的词性标注类(比如, 所有的词都标注为名词), 基于规则标注词性, 基于正则表达式标注词性, n-gram标注词性等等.



资料3.3: Classify Text With NLTK http://blog.csdn.net/fxjtoday/article/details/5862041 别看标题是英文的, 实际上内容是中英文混合的, 不过这个比上面一篇简单些. 主要就是使用nltk对一些姓名 性别进行训练, 并预测测试语料中的姓名是啥性别. 这篇文章能够让你对 分类, 样本特征稍微有个初步入门.



资料3.4 使用nltk从非结构化数据中抽取信息 http://blog.csdn.net/fxjtoday/article/details/5871386  这篇主要介绍了命名实体识别



4.使用nltk来处理中文资料
nltk 怎么样使用中文?这是个大问题。这么个工具目前只能比较好的处理英文和其他的一些拉丁语系，谁让别人的单词与单词之间有个空格隔开呢！中文汉字一个挨一个的，nltk在分词这一关就过不去了，分词没法分，剩下的就都做不了。唯一能做的， 就是对网上现有的中文语料进行处理，这些语料都分好了词，可以使用nltk进行类似与英文的处理。



python处理中文首先需要设置一下文本的编码， 文件的首行加上： #coding utf-8 这个是给python解释器识别的，然后文件保存的时候，还需要保存为utf-8的编码。

这些编码设置完了， ntlk还是处理不了中文。



nltk处理中文的第一步障碍就是中文资料不是分好词的， 词语与词语之间没有空格。要使用nltk对中文进行处理， 首先的第一步就是中文分词（台湾叫中文断词）。



目前python中文分词的包，我推荐使用结巴分词。 使用结巴分词，之后，就可以对输出文本使用nltk进行相关处理。



当然中文分词， 不应该成为使用nltk的障碍，或许很多人认为，既然用nltk，那么nltk就应该支持中文。但是我们得认清现实，现实就是nltk就是不支持处理中文，因此，这个给国内很多自然语言处理的研究人员有了研究的空间了，nltk既然没做中文分词，那么中国人就应该自己做了这个。一个口碑比较好的中文分词工具就是ICTCLAS中文分词。



当然，我个人觉得中国人自己开发的纯python实现的结巴分词也不错。



总的来说，nltk不提供中文分词，不应该纠结于此，并止步不前，我们完全可以使用其他的中文分词工具，将需要处理的资料分好词，然后再使用nltk进行处理，因此，这里就不多说中文分词的那点事了。如果你因为中文分词而分心，并转向到中文分词的研究之中，那么你就掉入了另外一个深坑之中。牢记本文的主题是nltk。当然需要多啰嗦一点的就是，nltk的默认词性标注集使用的是Penn Treebank 的词性标注集，因此，你选用中文分词模块的时候，最好能够使用和penn词性标注集差不多的中文分词工具，当然，不一样也没事。



资料4.1 使用python结巴分词对中文资料进行分词 https://github.com/fxsjy/jieba 结巴分词的github主页

资料4.2 基于python的中文分词的实现及应用 http://www.cnblogs.com/appler/archive/2012/02/02/2335834.html

资料4.3  对Python中文分词模块结巴分词算法过程的理解和分析 http://ddtcms.com/blog/archive/2013/2/4/69/jieba-fenci-suanfa-lijie/

资料4.4 宾州中文树库标记以及其解释， Penn Chinese Treebank Tag Set http://blog.csdn.net/neutblue/article/details/7375085



5.nltk的高级应用入门
啥叫高级啊？ 就是基础掌握了之后，开始运用实际工作了，就叫高级。比如什么统计推荐，评分，机器翻译，文本分类，舆情监控等等都是高级应用。

下面是些入门资料。

资料1： 通过nltk的机器学习方法实现论坛垃圾帖的过滤 http://blog.sina.com.cn/s/blog_630c58cb0100vkw3.html

资料2：利用nltk建立一个简单的词库 http://blog.sina.com.cn/s/blog_630c58cb0100vkix.html

资料3：利用概率分布进行关联规则挖掘 http://blog.sina.com.cn/s/blog_630c58cb0100vll0.html



6. nltk的精通
何谓精通？ 精通就是熟练的表达你的想法。

何谓精通一个工具？ 就是你想做什么， 你就能用这个工具顺利的完成。do everything you want with nltk.



至于如何精通，建议多看英文资料和多动手操练。nltk官方文档， 一些参与nltk的大学研究机构，北大，清华的语言研究以及国际语言研究机构acl所发的论文等等。



假设你目前真的熟练的掌握了nltk的各种玩法了，那么， 你精通的标志就是改造nltk， 使它功能更强，更优，更快，更方便。

比如：

6.1 集成结巴分词到nltk的分词器之中

6.2 在国内多弄几个地方，放置nltk_data数据包，方便大家下载

6.3 给nltk提供语料

等等，剩下的由你来补充。



最后说一句： nltk的中文资料确实不多，坑爹吧？相信很多人卡在了中文分词那一步。。。坚定的要求用nltk进行中文分词的朋友，还是先跳过这一步吧. 另外, 喜欢python和自然语言处理的朋友可以加我的QQ群:Python自然语言处理群(220373876), 欢迎来参与讨论.




























