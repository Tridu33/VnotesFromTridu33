











## 二值神经网路

现在的BNN（Binary Neural Network）的设计思路基本上都是从Binary Connect这篇文章延续下来的，STE框架，SGD算法，看了2014年使用EBP算法，发现也可以进行BNN的训练，为什么后期没有人继续发展了？





不使用先验知识与复杂训练策略，从头训练二值神经网络！ - 机器之心的文章 - 知乎
https://zhuanlan.zhihu.com/p/52344093


Hopfield神经网络？ - 尹瑞平的回答 - 知乎
https://www.zhihu.com/question/56994540/answer/191053894

SFFAI分享 | 杨朝晖：二值化网络 - 马上科普的文章 - 知乎
https://zhuanlan.zhihu.com/p/52271994

《Binarized Neural Networks: Neural Networks with Weights Constrained to +1 or −1 》阅读笔记 - 小打小闹的文章 - 知乎
https://zhuanlan.zhihu.com/p/24679842

什么是二值神经网络，它的前景如何？ - Ethan Sun的回答 - 知乎
https://www.zhihu.com/question/41957384/answer/119784634

Bengio大神在2016年发表了这篇Binary Neural Network，论文原文和代码链接见附录。

深度学习算法优化系列十 | 二值神经网络(Binary Neural Network，BNN) - BBuf的文章 - 知乎
https://zhuanlan.zhihu.com/p/106562387


补贴几篇paper,欢迎补充

XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks

Training deep neural networks with low precision multiplications

Deep learning with limited numerical precision

Training Binary Multilayer Neural Networks for Image Classification using Expectation Backpropagation

Probabilistic rounding in neural network learning with limited precision

Learning with limited numerical precision using the cascade-correlation algorithm

Training deep neural networks with binary weights during propagations

Binaryconnect: Training deep neural networks with binary weights during propagations

Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or-1

Bitwise neural networks

二值神经网络（Binary Neural Networks）最新综述 - PaperWeekly的文章 - 知乎
https://zhuanlan.zhihu.com/p/117285043


二值神经网络（Binary Neural Networks）综述论文 - 秦浩桐的文章 - 知乎
https://zhuanlan.zhihu.com/p/350439652

---------------------------------------------------------


对**可解释机器学习**的研究表明，神经网络的**推理**中存在**关键路径**(我理解这就是我们要找到的算法！！！只不过是被无脑train出来而已，因为不同网络识别内容不一样核心关键路径肯定不一样呀)，并且不同的网络结构遵循不同的模式。因此，根据层的重要性设计混合精度策略，并设计出对二值神经网络的信息流友好的新网络结构，也具有重要意义。

> 《计算系统的形式语义》把Haskell 的高阶函数，理解为泛函，理解为求解函数的函数，我的想法是正如机器学习的凸优化算法学习函数的函数，欧拉-拉格朗日方程 BP反向求导得到“函数的函数”应该长什么样子，进而BP反向求导算法。一阶形式系统嵌入到二阶形式系统(如二值网络)不可分。 从简单泛函 到 第二类拉格朗日方程，拉格朗日乘子法

1.5 图形化理解神经网络中的异或问题 - 如是的文章 - 知乎
https://zhuanlan.zhihu.com/p/25736962


计划写一篇二值神经网络 输入boolean semantic-named feature vector的 的model checking符号执行工具，或者二值网络编译成NuSMV输入文件然后“所有可能“语义命名描述的二值输入特征”保证网络能得到要求的“语义输出决策分类效果”，进而保证输出情况”是安全的。


# demo

- 从最简单的Xor开始训练

二值神经网络训练异或问题求解  https://www.cnblogs.com/21207-iHome/p/5227868.html  

手写haskell异或代码


手写c-like代码


手写汇编异或代码 verilog代码


- 井字棋 算法 “自动机形式系统代码实现” 与 “ANN网络实现”


训练简单的ANN神经网络$\mathcal{N}_1$实现人棋对战
https://blog.csdn.net/weixin_40651515/article/details/105756250

模型蒸馏，模型压缩，或者直接训练二值网络模型，总之就是强化学习得到$\mathcal{N}_2$开始二值网络$\mathcal{N}_2$

因为二值网络完全可以编译为等效的布尔电路，等价的状态迁移系统，等效的C-like代码$code_1$


自动机形式系统实现(输入是vector输入形式化命名的高阶抽象得到布尔向量$\vec{EndorFunctor}$，是0-1 真值表数据，可以通过CV自动编码机AntoEnCoder等得到Vector)
> 自函子是一类比较特殊的函子，它是一种将范畴映射到自身的函子 (A functor that maps a category to itself)。这个状态迁移系统描述local small范畴通过yoneda态射集合范畴得到的“状态编码”布尔向量$\vec{EndorFunctor}$



然后通过比较常规的算法实现代码$code_2$，和上述$code_1$比较是否是外部等价的（合同编程相同实现，或者理解为范畴等价，伽罗瓦连接，给定一个自然变换能相互推理形式化的等价性）
 https://github.com/BackMountainDevil/TicTacToe

**这样的可解释性的好处**：我突然想到个好处，如果得到二值网络$\mathcal{N}_2$对应决策系统的算法代码$code_1$表示，就能对二值符号化的输入输出进行“符号执行/形式验证”，保证决策算法不会疏漏各种返利组合的清醒，满足特定“合同编程”的正确性、安全性。(举例特斯拉自动驾驶算法撞死人，若model check枚举所有找不出反例则程序安全性鲁棒性得到保证)
















































