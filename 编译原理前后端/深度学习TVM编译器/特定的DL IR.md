# 1. 特定的DL IR








特定的DL IR

如果想学习tensorflow xla和tvm，需要对llvm掌握到什么程度？ - 杨军的回答 - 知乎
https://www.zhihu.com/question/300549540/answer/552805774



我个人的观点，深度学习编译器可以分解为前端、中端、后端三个层次。

1.前端

负责将用户描述的模型计算图转换成特定的DL IR(比如TF XLA里的HLO，以及TVM IR);

前端这个过程的复杂性比字面上的转换两个字实际复杂得多，因为涉及到是否对用户模型计算图进行全图编译，以及各种灵活的计算原语和控制结构的支持（考虑到深度学习的建模语言本质上是Turing complete的，可以撰写出任意复杂的描述，在编译器完备支持起来是有不小的工作量的，仅仅是多层条件嵌套的合适IR图的设计组织表示就需要一些精巧的设计来进行handle了，因为这并不是简单构建一个AST就足以满足接续环节要求的），这里就先不展开了。

2.中端

会在前端生成的DL IR上进行一系列图层面（这个图相较于用户描述的模型计算图会更为本质一些，所以可以做一些更激进的全局性质的图优化，当然，熟悉编译器开发的同学会知道，越往下走，也可能意味着失去一些宏观层面的信息，这本质上是一个trade-off ，所以在进入到深度学习编译器前端之前，也是有相当一部分图优化动作可以放在用户描述的模型计算图层面来完成的，比如我们之前的一个小工作）的优化，这方面的优化，很多会从经典的编译器领域借鉴过来，比如LICM，constant folding，dead node elimination，等等；

3.后端

会基于中端优化完的DL IR，进行我们通常称之为codegen的工作，而后端又可以细分为几个部分：


